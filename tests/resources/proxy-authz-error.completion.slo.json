{
    "api_base": "",
    "cache_hit": false,
    "cache_key": null,
    "call_type": "/v1/chat/completions",
    "completionStartTime": 1766001469.197747,
    "completion_tokens": 0,
    "cost_breakdown": null,
    "custom_llm_provider": null,
    "endTime": 1766001469.197747,
    "end_user": "",
    "error_information": {
        "error_class": "ProxyException",
        "error_code": "",
        "error_message": "",
        "llm_provider": "",
        "traceback": "  File \"/usr/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/usr/lib/python3.13/site-packages/fastapi/routing.py\", line 110, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/fastapi/routing.py\", line 380, in app\n    solved_result = await solve_dependencies(\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<6 lines>...\n    )\n    ^\n  File \"/usr/lib/python3.13/site-packages/fastapi/dependencies/utils.py\", line 673, in solve_dependencies\n    solved = await call(**solved_result.values)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.13/site-packages/litellm/proxy/auth/user_api_key_auth.py\", line 1236, in user_api_key_auth\n    user_api_key_auth_obj = await _user_api_key_auth_builder(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n    )\n    ^\n  File \"/usr/lib/python3.13/site-packages/litellm/proxy/auth/user_api_key_auth.py\", line 1196, in _user_api_key_auth_builder\n    return await UserAPIKeyAuthExceptionHandler._handle_authentication_error(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<6 lines>...\n    )\n    ^\n  File \"/usr/lib/python3.13/site-packages/litellm/proxy/auth/auth_exception_handler.py\", line 118, in _handle_authentication_error\n    raise e\n  File \"/usr/lib/python3.13/site-packages/litellm/proxy/auth/user_api_key_auth.py\", line 950, in _user_api_key_auth_builder\n    await can_key_call_model(\n    ...<4 lines>...\n    )\n  File \"/usr/lib/python3.13/site-packages/litellm/proxy/auth/auth_checks.py\", line 1790, in can_key_call_model\n    return _can_object_call_model(\n        model=model,\n    ...<4 lines>...\n        object_type=\"key\",\n    )\n  File \"/usr/lib/python3.13/site-packages/litellm/proxy/auth/auth_checks.py\", line 1745, in _can_object_call_model\n    raise ProxyException(\n    ...<6 lines>...\n    )\n"
    },
    "error_str": "",
    "guardrail_information": null,
    "hidden_params": {
        "additional_headers": null,
        "api_base": null,
        "batch_models": null,
        "cache_key": null,
        "litellm_model_name": null,
        "litellm_overhead_time_ms": null,
        "model_id": null,
        "response_cost": null,
        "usage_object": null
    },
    "id": "d178c151-3d6c-44b4-8573-a273fa9429fa",
    "messages": [
        {
            "content": "redacted-by-litellm",
            "role": "user"
        }
    ],
    "metadata": {
        "applied_guardrails": [],
        "cold_storage_object_key": null,
        "mcp_tool_call_metadata": null,
        "prompt_management_metadata": null,
        "requester_custom_headers": null,
        "requester_ip_address": null,
        "requester_metadata": null,
        "spend_logs_metadata": null,
        "usage_object": {
            "completion_tokens": 0,
            "completion_tokens_details": null,
            "prompt_tokens": 0,
            "prompt_tokens_details": null,
            "total_tokens": 0
        },
        "user_api_key_alias": null,
        "user_api_key_auth_metadata": {},
        "user_api_key_budget_reset_at": null,
        "user_api_key_end_user_id": null,
        "user_api_key_hash": "80f12c134701293d85cf92beb2538d28223c6c7b8984332c5afc1e94369f7d9a",
        "user_api_key_max_budget": null,
        "user_api_key_org_id": null,
        "user_api_key_request_route": "/v1/chat/completions",
        "user_api_key_spend": 0.0,
        "user_api_key_team_alias": null,
        "user_api_key_team_id": null,
        "user_api_key_user_email": null,
        "user_api_key_user_id": null,
        "vector_store_request_metadata": null
    },
    "model": "gpt-5-nano",
    "model_group": "",
    "model_id": "",
    "model_map_information": {
        "model_map_key": "",
        "model_map_value": null
    },
    "model_parameters": {},
    "prompt_tokens": 0,
    "request_tags": [],
    "requester_ip_address": null,
    "response": {
        "text": "redacted-by-litellm"
    },
    "response_cost": 0.0,
    "response_cost_failure_debug_info": null,
    "response_time": 0.00022602081298828125,
    "saved_cache_cost": 0.0,
    "standard_built_in_tools_params": {
        "file_search": null,
        "web_search_options": null
    },
    "startTime": 1766001469.197521,
    "status": "failure",
    "status_fields": {
        "guardrail_status": "not_run",
        "llm_api_status": "failure"
    },
    "stream": null,
    "total_tokens": 0,
    "trace_id": "076855f6-206b-40ce-aa08-c7c11530961a"
}
